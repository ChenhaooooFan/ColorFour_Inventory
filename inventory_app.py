import streamlit as st
import pandas as pd
import pdfplumber
import re
from collections import defaultdict
from io import BytesIO
from datetime import datetime
import os

st.set_page_config(page_title="NailVesta åº“å­˜ç³»ç»ŸğŸ†•", layout="centered")
st.title("ColorFour Inventory ç³»ç»Ÿ")

# ä¸Šä¼ æ–‡ä»¶ï¼ˆPDF æ”¯æŒå¤šé€‰ï¼‰
pdf_files = st.file_uploader("ä¸Šä¼  Picking List PDFï¼ˆå¯å¤šé€‰ï¼‰", type=["pdf"], accept_multiple_files=True)
csv_file = st.file_uploader("ä¸Šä¼ åº“å­˜è¡¨ CSV", type=["csv"])

# é€‰æ‹©è¦å‚ä¸ç»Ÿè®¡çš„ PDFï¼ˆé»˜è®¤å…¨é€‰ï¼‰
selected_pdfs = []
if pdf_files:
    selected_names = st.multiselect(
        "é€‰æ‹©è¦å‚ä¸ç»Ÿè®¡çš„ Picking List PDF",
        options=[f.name for f in pdf_files],
        default=[f.name for f in pdf_files]
    )
    selected_pdfs = [f for f in pdf_files if f.name in selected_names]

# â€”â€” æŒ‰é’®è§¦å‘ï¼šæ˜¯å¦æœ‰è¾¾äººæ¢è´§ â€”â€” #
if "show_exchange" not in st.session_state:
    st.session_state.show_exchange = False
if st.button("æœ‰è¾¾äººæ¢è´§å—ï¼Ÿ"):
    st.session_state.show_exchange = True

exchange_df = None
if st.session_state.show_exchange:
    st.info("è¯·ä¸Šä¼ æ¢è´§è®°å½•æ–‡ä»¶ï¼ˆCSV / Excelï¼‰ï¼Œå°†æ‰§è¡Œï¼šåŸæ¬¾ +1ã€æ¢è´§ -1ï¼ˆæ¯è¡Œå„ä¸€ä»¶ï¼‰")
    exchange_file = st.file_uploader("ä¸Šä¼ æ¢è´§è®°å½•", type=["csv", "xlsx"])
    if exchange_file:
        if exchange_file.name.endswith(".csv"):
            exchange_df = pd.read_csv(exchange_file)
        else:
            exchange_df = pd.read_excel(exchange_file)
        st.success("æ¢è´§è¡¨å·²ä¸Šä¼ ")

# ========= æ–‡æœ¬æ¸…æ´— & æ–­è¡Œä¿®å¤ =========
def normalize_text(t: str) -> str:
    t = t.replace("\u00ad", "").replace("\u200b", "").replace("\u00a0", " ")
    t = t.replace("â€“", "-").replace("â€”", "-")
    return t

def fix_orphan_digit_before_size(txt: str) -> str:
    """
    ä¿®å¤ï¼š
      NPJ011NPX01\n5-M  â†’ NPJ011NPX015-M
    """
    pattern = re.compile(
        r'(?P<prefix>(?:[A-Z]{3}\d{3}){0,3}[A-Z]{3}\d{2})\s*[\r\n]+\s*(?P<d>\d)\s*-\s*(?P<size>[SML])'
    )
    def _join(m): return f"{m.group('prefix')}{m.group('d')}-{m.group('size')}"
    prev, cur = None, txt
    while prev != cur:
        prev, cur = cur, pattern.sub(_join, cur)
    return cur

# â€”â€” Bundle æ‹†åˆ†ï¼ˆ1â€“4 ä»¶ï¼‰â€”â€”
def expand_bundle_or_single(sku_with_size: str, qty: int, counter: dict):
    sku_with_size = re.sub(r'\s+', '', sku_with_size.strip())
    if "-" not in sku_with_size:
        counter[sku_with_size] += qty
        return
    code, size = sku_with_size.split("-", 1)
    code, size = code.strip(), size.strip()

    if len(code) % 6 == 0 and 6 <= len(code) <= 24:
        segs = [code[i:i+6] for i in range(0, len(code), 6)]
        if all(re.fullmatch(r"[A-Z]{3}\d{3}", s) for s in segs):
            for s in segs:
                counter[f"{s}-{size}"] += qty
            return
    counter[sku_with_size] += qty

# â€”â€” ä¸»æµç¨‹ â€”â€” #
if selected_pdfs and csv_file:
    st.success("æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼Œå¼€å§‹å¤„ç†...")

    # è¯»å–åº“å­˜ CSVï¼ˆä¿æŒåŸé€»è¾‘ï¼‰
    stock_df = pd.read_csv(csv_file)
    stock_df.columns = [col.strip() for col in stock_df.columns]
    stock_col = [col for col in stock_df.columns if re.match(r"\d{2}/\d{2}", col)]
    if not stock_col:
        st.error("æœªæ‰¾åˆ°åº“å­˜æ—¥æœŸåˆ—ï¼ˆå¦‚ '06/03'ï¼‰")
        st.stop()
    stock_date_col = stock_col[0]
    stock_skus = set(stock_df["SKUç¼–ç "].astype(str).str.strip())

    # å¯¹è´¦æ•°æ®å®¹å™¨
    pdf_item_list = []
    pdf_sku_counts = {}
    pdf_nm001_counts = {}
    pdf_hb_counts = {}

    # æ­£åˆ™ï¼ˆè·¨è¡Œï¼‰
    SKU_BUNDLE = re.compile(r'((?:[A-Z]{3}\d{3}[\s\n]*){1,4}-[SML])', re.DOTALL)
    QTY_AFTER  = re.compile(r'\b([1-9]\d{0,2})\b')  # 1â€“3 ä½æ•°é‡ï¼›é¿å…æŠŠ 9+ ä½è®¢å•å·å½“æ•°é‡

    def _scan_holiday_bunny_qty(line: str) -> int:
        if not re.search(r'holiday\s*bunny', line, flags=re.I):
            return 0
        m = re.search(r'holiday\s*bunny.*?(\d{1,3})\s+\d{9,}', line, flags=re.I)
        if m:
            return int(m.group(1))
        if re.search(r'\d{9,}', line):
            nums = re.findall(r'\b(\d{1,3})\b', line)
            if nums:
                return int(nums[0])
        return 0

    for pf in selected_pdfs:
        # 1) æ ‡æ³¨ Item quantity
        with pdfplumber.open(pf) as pdf:
            first_page_text = normalize_text(pdf.pages[0].extract_text() or "")
            item_match = re.search(r'Item\s+quantity[:ï¼š]?\s*(\d+)', first_page_text, re.I)
            qty_val = int(item_match.group(1)) if item_match else ""

        # 2) æ•´ä»½ PDF æ‹¼æˆä¸€ä¸ªæ–‡æœ¬å—åè¯†åˆ«ï¼ˆè§£å†³è·¨å•å…ƒæ ¼/è·¨è¡Œ/é˜…è¯»é¡ºåºé—®é¢˜ï¼‰
        all_text = []
        with pdfplumber.open(pf) as pdf:
            for page in pdf.pages:
                all_text.append(normalize_text(page.extract_text() or ""))
        doc_text = "\n".join(all_text)
        doc_text = fix_orphan_digit_before_size(doc_text)

        sku_counts_single = defaultdict(int)

        # 2.1 æ‰«ææ‰€æœ‰ SKUï¼ˆ1â€“4 æ®µï¼Œè·¨è¡Œï¼‰
        for m in SKU_BUNDLE.finditer(doc_text):
            raw_sku = re.sub(r'\s+', '', m.group(1))     # å»æ‰ä»»ä½•ç©ºç™½
            # 2.2 SKU åé¢ 120 å­—ç¬¦å†…æ‰¾ç¬¬ä¸€ä¸ª 1â€“3 ä½æ•°å­—ä½œä¸ºæ•°é‡ï¼›æ‰¾ä¸åˆ°é»˜è®¤ 1
            lookahead = doc_text[m.end(): m.end() + 120]
            mq = QTY_AFTER.search(lookahead)
            qty = int(mq.group(1)) if mq else 1
            expand_bundle_or_single(raw_sku, qty, sku_counts_single)

        # 2.3 å…¼å®¹ç¼º SKU çš„â€œæ•°é‡+è®¢å•å·â€è¡Œï¼ˆä¿ç•™ä½ çš„å…œåº•é€»è¾‘ï¼‰
        for line in doc_text.split("\n"):
            m2 = re.search(r'^\s*(\d{1,3})\s+\d{9,}\s*$', line.strip())
            if m2:
                sku_counts_single[f"MISSING_{len(pdf_item_list)}"] += int(m2.group(1))

        pdf_sku_counts[pf.name] = sku_counts_single

        # 3) NM001 & Holiday Bunnyï¼ˆä»…å¯¹è´¦æç¤ºï¼Œä¸å‚ä¸æ‰£å‡ï¼‰
        nm001_qty_scan = 0
        hb_qty_scan = 0
        with pdfplumber.open(pf) as pdf:
            for page in pdf.pages:
                lines = (page.extract_text() or "").split("\n")
                for line in lines:
                    m_nm = re.search(r'\bNM001\b\s+(\d{1,3})\s+\d{9,}', line)
                    if m_nm:
                        nm001_qty_scan += int(m_nm.group(1))
                    hb_qty_scan += _scan_holiday_bunny_qty(line)
        pdf_nm001_counts[pf.name] = nm001_qty_scan
        pdf_hb_counts[pf.name] = hb_qty_scan

        # 4) è®¡ç®—è¯¥ PDF çš„æå–å‡ºè´§æ•°é‡ï¼ˆä¸å« MISSING_ï¼‰
        actual_total = sum(q for s, q in sku_counts_single.items() if not s.startswith("MISSING_"))

        # 5) çŠ¶æ€åˆ¤å®š
        if qty_val == "":
            status = "æ— æ ‡æ³¨"
        else:
            diff = actual_total - qty_val
            if diff == 0:
                status = "ä¸€è‡´"
            elif ("NM001" not in stock_skus) and (actual_total + nm001_qty_scan == qty_val):
                status = f"ä¸€è‡´ï¼ˆå·® {nm001_qty_scan} ä»¶ï¼Œå‡ä¸º NM001ï¼Œåº“å­˜æ— æ­¤ SKUï¼‰"
            elif (actual_total + hb_qty_scan == qty_val):
                status = f"ä¸€è‡´ï¼ˆå·® {hb_qty_scan} ä»¶ï¼Œå‡ä¸º Holiday Bunnyï¼Œæœªè¢«æ­£åˆ™è¯†åˆ«ï¼‰"
            elif ("NM001" not in stock_skus) and (actual_total + nm001_qty_scan + hb_qty_scan == qty_val):
                status = f"ä¸€è‡´ï¼ˆå·® {nm001_qty_scan + hb_qty_scan} ä»¶ï¼Œå…¶ä¸­ NM001 {nm001_qty_scan}ã€Holiday Bunny {hb_qty_scan}ï¼‰"
            else:
                status = f"ä¸ä¸€è‡´ï¼ˆå·® {diff}ï¼‰" if hb_qty_scan == 0 else f"ä¸ä¸€è‡´ï¼ˆå·® {diff}ï¼›Holiday Bunny æ‰«æåˆ° {hb_qty_scan} ä»¶ï¼‰"

        pdf_item_list.append({
            "PDFæ–‡ä»¶": pf.name,
            "Item quantity": qty_val,
            "æå–å‡ºè´§æ•°é‡": actual_total,
            "çŠ¶æ€": status
        })

    # â€”â€” æ˜¾ç¤º PDF å¯¹è´¦è¡¨ + åˆè®¡è¡Œ â€”â€” 
    st.subheader("å„ PDF çš„ Item quantity å¯¹è´¦è¡¨")
    pdf_df = pd.DataFrame(pdf_item_list)
    total_expected = pdf_df["Item quantity"].replace("", 0).astype(int).sum() if not pdf_df.empty else 0
    total_actual = pdf_df["æå–å‡ºè´§æ•°é‡"].sum() if not pdf_df.empty else 0
    nm001_total_scan = sum(pdf_nm001_counts.values())
    hb_total_scan = sum(pdf_hb_counts.values())

    if total_expected > 0:
        if total_actual == total_expected:
            total_status = "ä¸€è‡´"
        elif ("NM001" not in stock_skus) and (total_actual + nm001_total_scan == total_expected):
            total_status = f"ä¸€è‡´ï¼ˆå·® {nm001_total_scan} ä»¶ï¼Œå‡ä¸º NM001ï¼Œåº“å­˜æ— æ­¤ SKUï¼‰"
        elif (total_actual + hb_total_scan == total_expected):
            total_status = f"ä¸€è‡´ï¼ˆå·® {hb_total_scan} ä»¶ï¼Œå‡ä¸º Holiday Bunnyï¼Œæœªè¢«æ­£åˆ™è¯†åˆ«ï¼‰"
        elif ("NM001" not in stock_skus) and (total_actual + nm001_total_scan + hb_total_scan == total_expected):
            total_status = f"ä¸€è‡´ï¼ˆå·® {nm001_total_scan + hb_total_scan} ä»¶ï¼Œå…¶ä¸­ NM001 {nm001_total_scan}ã€Holiday Bunny {hb_total_scan}ï¼‰"
        else:
            total_status = f"ä¸ä¸€è‡´ï¼ˆå·® {total_actual - total_expected}ï¼›Holiday Bunny æ‰«æåˆ° {hb_total_scan} ä»¶ï¼‰"
    else:
        total_status = "â€”"

    if not pdf_df.empty:
        pdf_df = pd.concat([pdf_df, pd.DataFrame({
            "PDFæ–‡ä»¶": ["åˆè®¡"],
            "Item quantity": [total_expected],
            "æå–å‡ºè´§æ•°é‡": [total_actual],
            "çŠ¶æ€": [total_status]
        })], ignore_index=True)

    st.dataframe(pdf_df, use_container_width=True)

    if hb_total_scan > 0:
        st.info(f"æç¤ºï¼šæ‰«æåˆ° Holiday Bunny å…± {hb_total_scan} ä»¶ã€‚å¦‚æœæœªè‡ªåŠ¨è¯†åˆ«ï¼Œè¯·åœ¨ä¸‹é¢â€œç¼º SKU è¡¥å½•â€è¾“å…¥å…¶å¯¹åº”çš„ SKU åç¡®è®¤ã€‚")

    # â€”â€” åˆå¹¶æ‰€æœ‰ PDF çš„ SKU æ•°æ®ï¼ˆä¿æŒåŸé€»è¾‘ï¼Œè®¡æ•°ç”±å‰æ–‡å·²æ‹†åˆ†ï¼‰â€”â€”
    sku_counts_all = defaultdict(int)
    missing_lines = []
    raw_missing = []
    for pf_name, counts in pdf_sku_counts.items():
        for sku, qty in counts.items():
            if sku.startswith("MISSING_"):
                missing_lines.append(qty)
                raw_missing.append(f"{pf_name} ä¸­ç¼ºSKUçš„ {qty} ä»¶")
            else:
                sku_counts_all[sku] += qty

    # ç¼º SKU è¡¥å½•ï¼ˆæ”¯æŒ Bundle è¡¥å½•ï¼‰
    if missing_lines:
        st.warning("ä»¥ä¸‹å‡ºè´§è®°å½•ç¼º SKUï¼Œè¯·è¡¥å½•ï¼š")
        manual_entries = {}
        for i, raw in enumerate(raw_missing):
            manual_entries[i] = st.text_input(f"â€œ{raw}â€çš„ SKU æ˜¯ï¼š", key=f"miss_{i}")
        if st.button("ç¡®è®¤è¡¥å½•"):
            for i, sku in manual_entries.items():
                if sku and sku != "":
                    expand_bundle_or_single(sku.strip(), missing_lines[i], sku_counts_all)
            st.success("å·²å°†è¡¥å½• SKU æ·»åŠ è¿›åº“å­˜ç»Ÿè®¡")

    # â€”â€” æ¢è´§å¤„ç† â€”â€” 
    if exchange_df is not None:
        if "åŸæ¬¾å¼" in exchange_df.columns and "æ¢è´§æ¬¾å¼" in exchange_df.columns:
            for _, row in exchange_df.iterrows():
                original_sku = str(row["åŸæ¬¾å¼"]).strip()
                new_sku = str(row["æ¢è´§æ¬¾å¼"]).strip()
                if sku_counts_all.get(original_sku):
                    qty = sku_counts_all.pop(original_sku)
                    sku_counts_all[new_sku] += qty
                stock_df.loc[stock_df["SKUç¼–ç "] == original_sku, stock_date_col] += 1
                stock_df.loc[stock_df["SKUç¼–ç "] == new_sku, stock_date_col] -= 1
            st.success("æ¢è´§å¤„ç†å®Œæˆï¼šå·²æ›¿æ¢æå–æ•°é‡å¹¶è°ƒæ•´åº“å­˜ï¼ˆåŸæ¬¾ +1 / æ¢è´§ -1ï¼‰")
        else:
            st.warning("æ¢è´§è¡¨ä¸­å¿…é¡»åŒ…å«â€œåŸæ¬¾å¼â€å’Œâ€œæ¢è´§æ¬¾å¼â€ä¸¤åˆ—")

    # â€”â€” åˆå¹¶åº“å­˜æ•°æ®ï¼ˆä¿æŒåŸé€»è¾‘ï¼‰â€”â€”
    stock_df["Sold"] = stock_df["SKUç¼–ç "].map(sku_counts_all).fillna(0).astype(int)
    stock_df["New Stock"] = stock_df[stock_date_col] - stock_df["Sold"]
    summary_df = stock_df[["SKUç¼–ç ", stock_date_col, "Sold", "New Stock"]].copy()
    summary_df.columns = ["SKU", "Old Stock", "Sold Qty", "New Stock"]
    summary_df.index += 1
    summary_df.loc["åˆè®¡"] = [
        "â€”",
        summary_df["Old Stock"].sum(),
        summary_df["Sold Qty"].sum(),
        summary_df["New Stock"].sum()
    ]

    # å±•ç¤ºåº“å­˜æ›´æ–°ç»“æœ
    st.subheader("åº“å­˜æ›´æ–°ç»“æœ")
    st.dataframe(summary_df, use_container_width=True)

    # æ€»å¯¹è´¦ï¼ˆå¤ç”¨ NM001 / Holiday Bunny è§£é‡Šï¼‰
    total_sold = summary_df.loc["åˆè®¡", "Sold Qty"]
    if total_expected and total_expected > 0:
        if total_sold == total_expected:
            st.success(f"æå–æˆåŠŸï¼šå…± {total_sold} ä»¶ï¼Œä¸ PDF æ ‡æ³¨æ±‡æ€»ä¸€è‡´")
        elif ("NM001" not in stock_skus) and (total_sold + nm001_total_scan == total_expected):
            st.success(f"æå–æˆåŠŸï¼šå…± {total_sold} ä»¶ï¼ˆå·® {nm001_total_scan} ä»¶ï¼Œå‡ä¸º NM001ï¼Œåº“å­˜æ— æ­¤ SKUï¼‰ï¼Œä¸ PDF æ ‡æ³¨æ±‡æ€»ä¸€è‡´")
        elif (total_sold + hb_total_scan == total_expected):
            st.success(f"æå–æˆåŠŸï¼šå…± {total_sold} ä»¶ï¼ˆå·® {hb_total_scan} ä»¶ï¼Œå‡ä¸º Holiday Bunnyï¼Œæœªè¢«æ­£åˆ™è¯†åˆ«ï¼‰ï¼Œä¸ PDF æ ‡æ³¨æ±‡æ€»ä¸€è‡´")
        elif ("NM001" not in stock_skus) and (total_sold + nm001_total_scan + hb_total_scan == total_expected):
            st.success(f"æå–æˆåŠŸï¼šå…± {total_sold} ä»¶ï¼ˆå·® {nm001_total_scan + hb_total_scan} ä»¶ï¼Œå…¶ä¸­ NM001 {nm001_total_scan}ã€Holiday Bunny {hb_total_scan}ï¼‰ï¼Œä¸ PDF æ ‡æ³¨æ±‡æ€»ä¸€è‡´")
        else:
            if hb_total_scan > 0:
                st.error(f"æå–æ•°é‡ {total_sold} ä¸ PDF æ ‡æ³¨æ±‡æ€» {total_expected} ä¸ä¸€è‡´ï¼›å…¶ä¸­ Holiday Bunny æ‰«æåˆ° {hb_total_scan} ä»¶")
            else:
                st.error(f"æå–æ•°é‡ {total_sold} ä¸ PDF æ ‡æ³¨æ±‡æ€» {total_expected} ä¸ä¸€è‡´")
    else:
        st.warning("æœªè¯†åˆ« PDF ä¸­çš„ Item quantity")

    # å¯å¤åˆ¶ New Stock
    st.subheader("ä¸€é”®å¤åˆ¶ New Stock")
    new_stock_text = "\n".join(summary_df.iloc[:-1]["New Stock"].astype(str).tolist())
    st.code(new_stock_text, language="text")

    # ä¸‹è½½ Excel
    output = BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        summary_df.to_excel(writer, index_label="åºå·")
    st.download_button(
        label="ä¸‹è½½åº“å­˜æ›´æ–°è¡¨ Excel",
        data=output.getvalue(),
        file_name="åº“å­˜æ›´æ–°ç»“æœ.xlsx"
    )

    # ä¸Šä¼ å†å²è®°å½•
    history_file = "upload_history.csv"
    new_record = {
        "æ—¶é—´": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "PDFæ–‡ä»¶": "; ".join([f.name for f in selected_pdfs]),
        "åº“å­˜æ–‡ä»¶": csv_file.name,
        "PDFæ ‡æ³¨æ•°é‡": total_expected if total_expected else "",
        "æå–å‡ºè´§æ•°é‡": total_sold
    }
    if os.path.exists(history_file):
        history_df = pd.read_csv(history_file)
        history_df = pd.concat([history_df, pd.DataFrame([new_record])], ignore_index=True)
    else:
        history_df = pd.DataFrame([new_record])
    history_df.to_csv(history_file, index=False)

    st.subheader("ä¸Šä¼ å†å²è®°å½•")
    st.dataframe(history_df, use_container_width=True)

else:
    st.info("è¯·ä¸Šä¼ ä¸€ä¸ªæˆ–å¤šä¸ª Picking List PDF å’Œåº“å­˜ CSV ä»¥å¼€å§‹å¤„ç†ã€‚")
